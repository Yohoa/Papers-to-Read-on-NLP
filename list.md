# List of Papers to Read

**注意**: 忽略了部分knowlege base machine reading相关论文

## ACL

Annual Meeting of the Association for Computational Linguistics

### Accepted Long Papers of ACL 2018

- [Efficient and Robust Question Answering from Minimal Context over Documents](http://aclweb.org/anthology/P18-1160 )
- [Incorporating Chinese Characters of Words for Lexical Sememe Prediction](http://aclweb.org/anthology/P18-1227 )
- [ Multi-Granularity Hierarchical Attention Fusion Networks for Reading Comprehension and Question Answering](http://aclweb.org/anthology/P18-1158 )
- [Learning Domain-Sensitive and Sentiment-Aware Word Embeddings](http://aclweb.org/anthology/P18-1232)
- [Probabilistic FastText for Multi-Sense Word Embeddings](http://aclweb.org/anthology/P18-1001)
- [Accelerating Neural Transformer via an Average Attention Network](http://aclweb.org/anthology/P18-1166)
- [Did the Model Understand the Question?](http://aclweb.org/anthology/P18-1176 )
- [Baseline Needs More Love: On Simple Word-Embedding-Based Models and Associated Pooling Mechanisms](http://aclweb.org/anthology/P18-1041)
- [Multi-Relational Question Answering from Narratives: Machine Reading and Reasoning in Simulated Worlds](Multi-Relational Question Answering from Narratives: Machine Reading and Reasoning in Simulated Worlds)
- [Stochastic Answer Networks for Machine Reading Comprehension](http://aclweb.org/anthology/P18-1157)
- [Think Visually: Question Answering through Virtual Imagery](http://aclweb.org/anthology/P18-1242)
- [Large-Scale QA-SRL Parsing](http://aclweb.org/anthology/P18-1191)
- [Multimodal Affective Analysis Using Hierarchical Attention Strategy with Word-Level Alignment](http://aclweb.org/anthology/P18-1207)
- [Joint Training of Candidate Extraction and Answer Selection for Reading Comprehension](http://aclweb.org/anthology/P18-1159)
- [Question Condensing Networks for Answer Selection in Community Question Answering](http://aclweb.org/anthology/P18-1162 )
- [How Much Attention Do You Need? A Granular Analysis of Neural Machine Translation Architectures](http://aclweb.org/anthology/P18-1167)
- [Extracting Relational Facts by an End-to-End Neural Model with Copy Mechanism](http://aclweb.org/anthology/P18-1047)

### Accepted Short Papers of ACL 2018

- [Improving Beam Search by Removing Monotonic Constraint for Neural Machine Translation](http://aclweb.org/anthology/P18-2054)
- [GNEG: Graph-Based Negative Sampling for word2vec](http://aclweb.org/anthology/P18-2090)
- [Long Short-Term Memory as a Dynamically Computed Element-wise Weighted Sum](http://aclweb.org/anthology/P18-2116)
- [Unsupervised Learning of Style-sensitive Word Vectors](http://aclweb.org/anthology/P18-2091)
- [Using pseudo-senses for improving the extraction of synonyms from word embeddings](http://aclweb.org/anthology/P18-2056 )
- [A Co-Matching Model for Multi-choice Reading Comprehension](http://aclweb.org/anthology/P18-2118)
- [Learning Matching Models with Weak Supervision for Response Selection in Retrieval-based Chatbots](http://aclweb.org/anthology/P18-2067)
- [Exploring Semantic Properties of Sentence Embeddings](http://aclweb.org/anthology/P18-2100)
- [A Rank-Based Similarity Metric for Word Embeddings](http://aclweb.org/anthology/P18-2088)

### Accepted Student Papers of ACL 2018

- [Graph-based Filtering of Out-of-Vocabulary Words for Encoder-Decoder Models](http://aclweb.org/anthology/P18-3016 )

### System Demonstration Papers of ACL 2018

- [Jack the Reader -- A Machine Reading Framework](http://aclweb.org/anthology/P18-4005)
- [A Flexible, Efficient and Accurate Framework for Community Question Answering Pipelines](http://aclweb.org/anthology/P18-4023 )

## EMNLP

### Accepted Long Papers

- [A Stable and Effective Learning Strategy for Trainable Greedy Decoding](http://cn.arxiv.org/abs/1804.07915)
- [Unsupervised Multilingual Word Embeddings](http://cn.arxiv.org/abs/1808.08933v1)
- [Is it Time to Swish? Comparing Deep Learning Activation Functions Across NLP tasks](https://public.ukp.informatik.tu-darmstadt.de/UKP_Webpage/publications/2018/2018_EMNLP_ActivationFunctions_CR.pdf)
- [Explaining Character-Aware Neural Networks for Word-Level Prediction: Do They Discover Linguistic Rules?](cn.arxiv.org/abs/1808.09551)
- [Disambiguated skip-gram model]
- [Neural Compositional Denotational Semantics for Question Answering](http://cn.arxiv.org/abs/1808.09942?context=cs)
- [Sanskrit Word Segmentation Using Character-level Recurrent and Convolutional Neural Networks]()
- [Attention-Guided Answer Distillation for Machine Reading Comprehension](http://cn.arxiv.org/abs/1808.07644)
- [Joint Multitask Learning for Community Question Answering Using Task-Specific Embeddings]()
- [A Nil-Aware Answer Extraction Framework for Question Answering](https://openreview.net/pdf?id=rJBiunlAW)
- [Knowledge Base Question Answering via Encoding of Complex Query Graphs]()
- [Pyramidal Recurrent Unit for Language Modeling](http://cn.arxiv.org/abs/1808.09029v1)
- [Evaluating Theory of Mind in Question Answering](http://cn.arxiv.org/abs/1808.09352)
- [Dissecting Contextual Word Embeddings: Architecture and Representation](http://cn.arxiv.org/abs/1808.08949?context=cs)
- [Sentiment Classification towards Question-Answering with Hierarchical Matching Network]()
- [Why Self-Attention? A Targeted Evaluation of Neural Machine Translation Architectures](cn.arxiv.org/abs/1808.08946?context=cs.CL)
- [Cross-Pair Text Representations for Answer Sentence Selection]()
- [Toward Understanding and Explaining Complex Deep Models in NLP]()
- [A strong baseline for question relevancy ranking](http://cn.arxiv.org/abs/1808.08836)
- [How to represent a word and predict it, too: improving tied architectures for language modelling]()
- [Decipherment of Substitution Ciphers with Neural Language Models]()
- [Bi-LSTMs Are State-of-the-art for Chinese Word Segmentation]()
- [Semantic Linking in Convolutional Neural Networks for Answer Sentence Selection]()
- [Word Embeddings for Code-Mixed Language Processing]()
- [Utilizing Character and Word Embeddings for Text Normalization with Sequence-to-Sequence Models](http://cn.arxiv.org/pdf/1809.01534v1)
- []